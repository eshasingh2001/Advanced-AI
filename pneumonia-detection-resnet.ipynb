{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom sklearn.metrics import classification_report,confusion_matrix\nimport ipywidgets as widgets\nimport io\nfrom PIL import Image\nfrom IPython.display import display,clear_output\nfrom warnings import filterwarnings\n","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2023-11-14T16:16:01.184258Z","iopub.execute_input":"2023-11-14T16:16:01.184612Z","iopub.status.idle":"2023-11-14T16:16:13.868616Z","shell.execute_reply.started":"2023-11-14T16:16:01.184580Z","shell.execute_reply":"2023-11-14T16:16:13.867726Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Color","metadata":{}},{"cell_type":"code","source":"colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\ncolors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\ncolors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']\n\nsns.palplot(colors_dark)\nsns.palplot(colors_green)\nsns.palplot(colors_red)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:16:13.870131Z","iopub.execute_input":"2023-11-14T16:16:13.870711Z","iopub.status.idle":"2023-11-14T16:16:14.182813Z","shell.execute_reply.started":"2023-11-14T16:16:13.870682Z","shell.execute_reply":"2023-11-14T16:16:14.181508Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 500x100 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC8ElEQVR4nO3asU4iARSF4QsaSYxAtESo7Gx8A1sfyze1cBIeQIiFicwWGzfZAh3IMbPjfl/LFCfX4s+Ao7Zt2wKAoHHfAwD4ecQFgDhxASBOXACIExcA4sQFgDhxASDutMtDu92u1ut1TafTGo1G370JgH9U27a12WxqsVjUeLz//aRTXNbrda1Wq9g4AIataZpaLpd7P+8Ul+l0WlVV19fXn5aKv11eXvY9YZDu7u76njBIDw8PfU8YnNvb274nDM52u637+/s/XdinU1w+vgobj8ficoCTk5O+JwzS2dlZ3xMG6fz8vO8Jg3NxcdH3hMH66icSpQAgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEg7rTLQ23bVlXVbrf71jE/zfv7e98TBunt7a3vCYP0+vra94TB2W63fU8YnI+bfXRhn1H71RNV9fT0VDc3N5llAAxe0zS1XC73ft7pzeXq6qqqqp6fn2s+n2eW/QdeXl5qtVpV0zQ1m836njMIbnYcdzucmx2nbdvabDa1WCw+fa5TXMbj3z/NzOdzf4QjzGYzdzuQmx3H3Q7nZofr8pLhB30A4sQFgLhOcZlMJvX4+FiTyeS79/wo7nY4NzuOux3Ozb5Xp/8WA4BD+FoMgDhxASBOXACIExcA4sQFgDhxASBOXACIExcA4n4BnrNuSvMY+NgAAAAASUVORK5CYII="},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x100 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC+UlEQVR4nO3aT4rTcBjH4be1GlDbwqyktAsZcKEn8AJ6AvU4c9NZTKAHmDqCf2hcDKgI1bR8h5jxeVaB/BYvbxcfknTSdV1XABA0HXoAAO4fcQEgTlwAiBMXAOLEBYA4cQEgTlwAiJv1ObTf72u73dZ8Pq/JZHLXMwHwj+q6rna7Xa1Wq5pODz+f9IrLdrutzWYTGw6AcWvbttbr9cH7veIyn89vL14/q5p5k9bXm1cvhh5hlGaP90OPMErnb54PPcLofHj5fugRRudm96nevnr3swsH9IrLj1dhs2lNxKW3h02v9fKbWSMup2iePBp6hNF5ungy9Aij9bdPJEoBQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQJy4ABAnLgDEiQsAceICQNysz6Gu624vvu2ru8tp7pmvn78NPcIodQ/2Q48wSp9vvgw9wuh8vL4ZeoTRudl9qqpfunDApPvbiaq6vLys8/PzzGQAjF7btrVerw/e7/XkcnZ2VlVVV1dXtVwuM5P9B66vr2uz2VTbtrVYLIYeZxTs7DT2djw7O03XdbXb7Wq1Wv3xXK+4TKe3n2aWy6Uf4QSLxcLejmRnp7G349nZ8fo8ZPigD0CcuAAQ1ysuTdPUxcVFNU1z1/PcK/Z2PDs7jb0dz87uVq9/iwHAMbwWAyBOXACIExcA4sQFgDhxASBOXACIExcA4sQFgLjvKtBvVfO0ce0AAAAASUVORK5CYII="},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 500x100 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAZcAAABlCAYAAACBS66rAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAC+0lEQVR4nO3av27aYBSH4QMkQqkKVEhdEEyZO7RL915I1TvJnWaIJS4AqnSIgjv0j9SB1KBf5Dp9ntUejg6gV5/NqG3btgAgaNz3AAC8POICQJy4ABAnLgDEiQsAceICQJy4ABB30eWmw+FQ2+22ZrNZjUaj554JgH9U27a13+9rtVrVeHz8fNIpLtvttjabTWw4AIataZpar9dHr3eKy2w2q6qqd2/e1MTJpbPr5bLvEQbp027X9wiD9OHjx75HGJy3nz/3PcLg7O/v6/2XL7+7cEynuPx6FDYZjWryxDGIP11OJn2PMEhXvmNneX152fcIgzN79arvEQbrb69I/IoBiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiBMXAOLEBYA4cQEgTlwAiLvoclPbtlVV9di2VYfDsw70kjw8PvY9wiB98x07y9eHh75HGJyr+/u+Rxic/c+d/erCMaP2b3dU1e3tbV1fX2cmA2Dwmqap9Xp99Hqnk8tyuayqqru7u1osFpnJ/gO73a42m001TVPz+bzvcQbBzs5jb6ezs/O0bVv7/b5Wq9WT93WKy3j849XMYrHwIZxhPp/b24ns7Dz2djo7O12XQ4YX+gDEiQsAcZ3iMp1O6+bmpqbT6XPP86LY2+ns7Dz2djo7e16d/i0GAKfwWAyAOHEBIE5cAIgTFwDixAWAOHEBIE5cAIgTFwDivgN0oHFgMtTbswAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Data Preperation","metadata":{}},{"cell_type":"code","source":"labels = ['NORMAL','PNEUMONIA']","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:16:14.185141Z","iopub.execute_input":"2023-11-14T16:16:14.186045Z","iopub.status.idle":"2023-11-14T16:16:14.191935Z","shell.execute_reply.started":"2023-11-14T16:16:14.185994Z","shell.execute_reply":"2023-11-14T16:16:14.190764Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"X_train = []\ny_train = []\nimage_size = 128\nfor i in labels:\n    folderPath = os.path.join('/kaggle/input/labeled-chest-xray-images/chest_xray','test',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size, image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nfor i in labels:\n    folderPath = os.path.join('/kaggle/input/labeled-chest-xray-images/chest_xray','train',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size,image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nX_train = np.array(X_train)\ny_train = np.array(y_train)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:16:14.195636Z","iopub.execute_input":"2023-11-14T16:16:14.196546Z","iopub.status.idle":"2023-11-14T16:18:29.854206Z","shell.execute_reply.started":"2023-11-14T16:16:14.196500Z","shell.execute_reply":"2023-11-14T16:18:29.853320Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"100%|██████████| 234/234 [00:07<00:00, 33.13it/s]\n100%|██████████| 390/390 [00:05<00:00, 72.67it/s]\n100%|██████████| 1349/1349 [00:48<00:00, 27.89it/s]\n100%|██████████| 3883/3883 [01:13<00:00, 52.73it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We start off by appending all the images from the  directories into a Python list and then converting them into numpy arrays after resizing it.","metadata":{}},{"cell_type":"code","source":"k=0\nfig, ax = plt.subplots(1,2,figsize=(20,20))\nfig.text(s='Sample Image From Each Label',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.62,x=0.4,alpha=0.8)\nfor i in labels:\n    j=0\n    while True :\n        if y_train[j]==i:\n            ax[k].imshow(X_train[j])\n            ax[k].set_title(y_train[j])\n            ax[k].axis('off')\n            k+=1\n            break\n        j+=1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-11-14T16:34:10.851046Z","iopub.execute_input":"2023-11-14T16:34:10.851448Z","iopub.status.idle":"2023-11-14T16:34:11.415319Z","shell.execute_reply.started":"2023-11-14T16:34:10.851418Z","shell.execute_reply":"2023-11-14T16:34:11.414110Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_48/986177961.py:8: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  if y_train[j]==i:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[40], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m j\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m :\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m==\u001b[39mi:\n\u001b[1;32m      9\u001b[0m         ax[k]\u001b[38;5;241m.\u001b[39mimshow(X_train[j])\n\u001b[1;32m     10\u001b[0m         ax[k]\u001b[38;5;241m.\u001b[39mset_title(y_train[j])\n","\u001b[0;31mIndexError\u001b[0m: index 5270 is out of bounds for axis 0 with size 5270"],"ename":"IndexError","evalue":"index 5270 is out of bounds for axis 0 with size 5270","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 2000x2000 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"X_train, y_train = shuffle(X_train,y_train, random_state=101)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:30.668937Z","iopub.execute_input":"2023-11-14T16:18:30.669244Z","iopub.status.idle":"2023-11-14T16:18:30.758939Z","shell.execute_reply.started":"2023-11-14T16:18:30.669216Z","shell.execute_reply":"2023-11-14T16:18:30.757938Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:30.760219Z","iopub.execute_input":"2023-11-14T16:18:30.760534Z","iopub.status.idle":"2023-11-14T16:18:30.766541Z","shell.execute_reply.started":"2023-11-14T16:18:30.760508Z","shell.execute_reply":"2023-11-14T16:18:30.765545Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(5856, 128, 128, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"**Image Data Augmentation**: Image data augmentation is a technique that can be used to artificially expand the size of a training dataset by creating modified versions of images in the dataset. It uses techniques such as flipping, zooming, padding, cropping, etc.<br><br>\nData augmentation makes the model more robust to slight variations, and hence *prevents the model from overfitting.*\n<br><br>\nTo do so using Keras, we use the function **ImageDataGenerator** ","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=30,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\ndatagen.fit(X_train)\nX_train.shape","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-14T16:18:30.767640Z","iopub.execute_input":"2023-11-14T16:18:30.767996Z","iopub.status.idle":"2023-11-14T16:18:31.448344Z","shell.execute_reply.started":"2023-11-14T16:18:30.767959Z","shell.execute_reply":"2023-11-14T16:18:31.447410Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(5856, 128, 128, 3)"},"metadata":{}}]},{"cell_type":"markdown","source":"Dividing the dataset into **Training** and **Testing** sets.","metadata":{}},{"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:31.449678Z","iopub.execute_input":"2023-11-14T16:18:31.450196Z","iopub.status.idle":"2023-11-14T16:18:31.537599Z","shell.execute_reply.started":"2023-11-14T16:18:31.450159Z","shell.execute_reply":"2023-11-14T16:18:31.536808Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"y_train_new = []\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train = y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\n\ny_test_new = []\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:31.541188Z","iopub.execute_input":"2023-11-14T16:18:31.541494Z","iopub.status.idle":"2023-11-14T16:18:31.553202Z","shell.execute_reply.started":"2023-11-14T16:18:31.541467Z","shell.execute_reply":"2023-11-14T16:18:31.552184Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Transfer Learning","metadata":{}},{"cell_type":"markdown","source":"Deep convolutional neural network models may take days or even weeks to train on very large datasets.\n\nA way to short-cut this process is to re-use the model weights from pre-trained models that were developed for standard computer vision benchmark datasets, such as the ImageNet image recognition tasks. Top performing models can be downloaded and used directly, or integrated into a new model for your own computer vision problems.\n\nIn this notebook, I'll be using the **EfficientNetB0** model which will use the weights from the **ImageNet** dataset.\n\nThe include_top parameter is set to *False* so that the network doesn't include the top layer/ output layer from the pre-built model which allows us to add our own output layer depending upon our use case!","metadata":{}},{"cell_type":"code","source":"\nfrom tensorflow.keras.applications import ResNet152V2\nresnet = ResNet152V2(weights='imagenet', include_top=False,input_shape=(image_size,image_size,3))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:31.554247Z","iopub.execute_input":"2023-11-14T16:18:31.554531Z","iopub.status.idle":"2023-11-14T16:18:47.117702Z","shell.execute_reply.started":"2023-11-14T16:18:31.554506Z","shell.execute_reply":"2023-11-14T16:18:47.116700Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n234545216/234545216 [==============================] - 8s 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"#effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:47.118995Z","iopub.execute_input":"2023-11-14T16:18:47.119340Z","iopub.status.idle":"2023-11-14T16:18:47.123471Z","shell.execute_reply.started":"2023-11-14T16:18:47.119313Z","shell.execute_reply":"2023-11-14T16:18:47.122463Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"**GlobalAveragePooling2D** -> This layer acts similar to the Max Pooling layer in CNNs, the only difference being is that it uses the Average values instead of the Max value while *pooling*. This really helps in decreasing the computational load on the machine while training.\n<br><br>\n**Dropout** -> This layer omits some of the neurons at each step from the layer making the neurons more independent from the neibouring neurons. It helps in avoiding overfitting. Neurons to be ommitted are selected at random. The **rate** parameter is the liklihood of a neuron activation being set to 0, thus dropping out the neuron\n\n**Dense** -> This is the output layer which classifies the image into 1 of the 4 possible classes. It uses the **softmax** function which is a generalization of the sigmoid function.","metadata":{}},{"cell_type":"code","source":"model = resnet.output\nmodel = tf.keras.layers.GlobalAveragePooling2D()(model)\nmodel = tf.keras.layers.Dropout(rate=0.5)(model)\nmodel = tf.keras.layers.Dense(2,activation='softmax')(model)\nmodel = tf.keras.models.Model(inputs=resnet.input, outputs = model)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:47.124742Z","iopub.execute_input":"2023-11-14T16:18:47.125146Z","iopub.status.idle":"2023-11-14T16:18:47.207737Z","shell.execute_reply.started":"2023-11-14T16:18:47.125110Z","shell.execute_reply":"2023-11-14T16:18:47.206952Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"scrolled":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-11-14T16:18:47.209039Z","iopub.execute_input":"2023-11-14T16:18:47.209430Z","iopub.status.idle":"2023-11-14T16:18:48.680896Z","shell.execute_reply.started":"2023-11-14T16:18:47.209394Z","shell.execute_reply":"2023-11-14T16:18:48.680010Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\n Layer (type)                Output Shape                 Param #   Connected to                  \n==================================================================================================\n input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n                                                                                                  \n conv1_pad (ZeroPadding2D)   (None, 134, 134, 3)          0         ['input_1[0][0]']             \n                                                                                                  \n conv1_conv (Conv2D)         (None, 64, 64, 64)           9472      ['conv1_pad[0][0]']           \n                                                                                                  \n pool1_pad (ZeroPadding2D)   (None, 66, 66, 64)           0         ['conv1_conv[0][0]']          \n                                                                                                  \n pool1_pool (MaxPooling2D)   (None, 32, 32, 64)           0         ['pool1_pad[0][0]']           \n                                                                                                  \n conv2_block1_preact_bn (Ba  (None, 32, 32, 64)           256       ['pool1_pool[0][0]']          \n tchNormalization)                                                                                \n                                                                                                  \n conv2_block1_preact_relu (  (None, 32, 32, 64)           0         ['conv2_block1_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv2_block1_1_conv (Conv2  (None, 32, 32, 64)           4096      ['conv2_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv2_block1_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block1_2_pad (ZeroPa  (None, 34, 34, 64)           0         ['conv2_block1_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv2_block1_2_conv (Conv2  (None, 32, 32, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv2_block1_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block1_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block1_0_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv2_block1_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block1_out (Add)      (None, 32, 32, 256)          0         ['conv2_block1_0_conv[0][0]', \n                                                                     'conv2_block1_3_conv[0][0]'] \n                                                                                                  \n conv2_block2_preact_bn (Ba  (None, 32, 32, 256)          1024      ['conv2_block1_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv2_block2_preact_relu (  (None, 32, 32, 256)          0         ['conv2_block2_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv2_block2_1_conv (Conv2  (None, 32, 32, 64)           16384     ['conv2_block2_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv2_block2_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block2_2_pad (ZeroPa  (None, 34, 34, 64)           0         ['conv2_block2_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv2_block2_2_conv (Conv2  (None, 32, 32, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv2_block2_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block2_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block2_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block2_out (Add)      (None, 32, 32, 256)          0         ['conv2_block1_out[0][0]',    \n                                                                     'conv2_block2_3_conv[0][0]'] \n                                                                                                  \n conv2_block3_preact_bn (Ba  (None, 32, 32, 256)          1024      ['conv2_block2_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv2_block3_preact_relu (  (None, 32, 32, 256)          0         ['conv2_block3_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv2_block3_1_conv (Conv2  (None, 32, 32, 64)           16384     ['conv2_block3_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv2_block3_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv2_block3_2_pad (ZeroPa  (None, 34, 34, 64)           0         ['conv2_block3_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv2_block3_2_conv (Conv2  (None, 16, 16, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv2_block3_2_bn (BatchNo  (None, 16, 16, 64)           256       ['conv2_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv2_block3_2_relu (Activ  (None, 16, 16, 64)           0         ['conv2_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n max_pooling2d (MaxPooling2  (None, 16, 16, 256)          0         ['conv2_block2_out[0][0]']    \n D)                                                                                               \n                                                                                                  \n conv2_block3_3_conv (Conv2  (None, 16, 16, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv2_block3_out (Add)      (None, 16, 16, 256)          0         ['max_pooling2d[0][0]',       \n                                                                     'conv2_block3_3_conv[0][0]'] \n                                                                                                  \n conv3_block1_preact_bn (Ba  (None, 16, 16, 256)          1024      ['conv2_block3_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block1_preact_relu (  (None, 16, 16, 256)          0         ['conv3_block1_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block1_1_conv (Conv2  (None, 16, 16, 128)          32768     ['conv3_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block1_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block1_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block1_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block1_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block1_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block1_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block1_0_conv (Conv2  (None, 16, 16, 512)          131584    ['conv3_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block1_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block1_out (Add)      (None, 16, 16, 512)          0         ['conv3_block1_0_conv[0][0]', \n                                                                     'conv3_block1_3_conv[0][0]'] \n                                                                                                  \n conv3_block2_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block1_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block2_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block2_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block2_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block2_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block2_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block2_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block2_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block2_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block2_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block2_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block2_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block2_out (Add)      (None, 16, 16, 512)          0         ['conv3_block1_out[0][0]',    \n                                                                     'conv3_block2_3_conv[0][0]'] \n                                                                                                  \n conv3_block3_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block2_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block3_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block3_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block3_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block3_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block3_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block3_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block3_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block3_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block3_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block3_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block3_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block3_out (Add)      (None, 16, 16, 512)          0         ['conv3_block2_out[0][0]',    \n                                                                     'conv3_block3_3_conv[0][0]'] \n                                                                                                  \n conv3_block4_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block3_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block4_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block4_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block4_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block4_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block4_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block4_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block4_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block4_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block4_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block4_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block4_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block4_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block4_out (Add)      (None, 16, 16, 512)          0         ['conv3_block3_out[0][0]',    \n                                                                     'conv3_block4_3_conv[0][0]'] \n                                                                                                  \n conv3_block5_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block4_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block5_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block5_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block5_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block5_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block5_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block5_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block5_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block5_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block5_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block5_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block5_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block5_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block5_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block5_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block5_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block5_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block5_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block5_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block5_out (Add)      (None, 16, 16, 512)          0         ['conv3_block4_out[0][0]',    \n                                                                     'conv3_block5_3_conv[0][0]'] \n                                                                                                  \n conv3_block6_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block5_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block6_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block6_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block6_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block6_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block6_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block6_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block6_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block6_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block6_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block6_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block6_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block6_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block6_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block6_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block6_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block6_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block6_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block6_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block6_out (Add)      (None, 16, 16, 512)          0         ['conv3_block5_out[0][0]',    \n                                                                     'conv3_block6_3_conv[0][0]'] \n                                                                                                  \n conv3_block7_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block6_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block7_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block7_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block7_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block7_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block7_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block7_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block7_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block7_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block7_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block7_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block7_2_conv (Conv2  (None, 16, 16, 128)          147456    ['conv3_block7_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block7_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block7_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block7_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block7_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block7_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block7_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block7_out (Add)      (None, 16, 16, 512)          0         ['conv3_block6_out[0][0]',    \n                                                                     'conv3_block7_3_conv[0][0]'] \n                                                                                                  \n conv3_block8_preact_bn (Ba  (None, 16, 16, 512)          2048      ['conv3_block7_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv3_block8_preact_relu (  (None, 16, 16, 512)          0         ['conv3_block8_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv3_block8_1_conv (Conv2  (None, 16, 16, 128)          65536     ['conv3_block8_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv3_block8_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block8_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block8_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block8_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv3_block8_2_pad (ZeroPa  (None, 18, 18, 128)          0         ['conv3_block8_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv3_block8_2_conv (Conv2  (None, 8, 8, 128)            147456    ['conv3_block8_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv3_block8_2_bn (BatchNo  (None, 8, 8, 128)            512       ['conv3_block8_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv3_block8_2_relu (Activ  (None, 8, 8, 128)            0         ['conv3_block8_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n max_pooling2d_1 (MaxPoolin  (None, 8, 8, 512)            0         ['conv3_block7_out[0][0]']    \n g2D)                                                                                             \n                                                                                                  \n conv3_block8_3_conv (Conv2  (None, 8, 8, 512)            66048     ['conv3_block8_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv3_block8_out (Add)      (None, 8, 8, 512)            0         ['max_pooling2d_1[0][0]',     \n                                                                     'conv3_block8_3_conv[0][0]'] \n                                                                                                  \n conv4_block1_preact_bn (Ba  (None, 8, 8, 512)            2048      ['conv3_block8_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block1_preact_relu (  (None, 8, 8, 512)            0         ['conv4_block1_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block1_1_conv (Conv2  (None, 8, 8, 256)            131072    ['conv4_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block1_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block1_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block1_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block1_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block1_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block1_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block1_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block1_0_conv (Conv2  (None, 8, 8, 1024)           525312    ['conv4_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block1_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block1_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_0_conv[0][0]', \n                                                                     'conv4_block1_3_conv[0][0]'] \n                                                                                                  \n conv4_block2_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block1_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block2_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block2_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block2_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block2_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block2_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block2_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block2_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block2_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block2_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block2_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block2_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block2_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block2_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_out[0][0]',    \n                                                                     'conv4_block2_3_conv[0][0]'] \n                                                                                                  \n conv4_block3_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block2_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block3_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block3_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block3_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block3_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block3_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block3_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block3_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block3_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block3_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block3_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block3_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block3_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block3_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block2_out[0][0]',    \n                                                                     'conv4_block3_3_conv[0][0]'] \n                                                                                                  \n conv4_block4_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block3_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block4_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block4_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block4_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block4_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block4_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block4_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block4_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block4_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block4_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block4_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block4_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block4_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block4_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block3_out[0][0]',    \n                                                                     'conv4_block4_3_conv[0][0]'] \n                                                                                                  \n conv4_block5_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block4_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block5_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block5_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block5_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block5_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block5_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block5_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block5_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block5_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block5_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block5_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block5_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block5_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block5_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block4_out[0][0]',    \n                                                                     'conv4_block5_3_conv[0][0]'] \n                                                                                                  \n conv4_block6_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block5_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block6_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block6_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block6_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block6_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block6_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block6_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block6_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block6_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block6_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block6_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block6_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block6_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block5_out[0][0]',    \n                                                                     'conv4_block6_3_conv[0][0]'] \n                                                                                                  \n conv4_block7_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block6_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block7_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block7_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block7_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block7_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block7_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block7_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block7_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block7_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block7_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block7_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block7_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block7_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block7_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block7_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block7_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block7_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block7_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block7_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block7_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block6_out[0][0]',    \n                                                                     'conv4_block7_3_conv[0][0]'] \n                                                                                                  \n conv4_block8_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block7_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block8_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block8_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block8_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block8_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block8_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block8_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block8_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block8_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block8_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block8_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block8_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block8_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block8_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block8_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block8_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block8_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block8_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block8_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block8_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block7_out[0][0]',    \n                                                                     'conv4_block8_3_conv[0][0]'] \n                                                                                                  \n conv4_block9_preact_bn (Ba  (None, 8, 8, 1024)           4096      ['conv4_block8_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv4_block9_preact_relu (  (None, 8, 8, 1024)           0         ['conv4_block9_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv4_block9_1_conv (Conv2  (None, 8, 8, 256)            262144    ['conv4_block9_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv4_block9_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block9_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block9_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block9_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block9_2_pad (ZeroPa  (None, 10, 10, 256)          0         ['conv4_block9_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv4_block9_2_conv (Conv2  (None, 8, 8, 256)            589824    ['conv4_block9_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv4_block9_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block9_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv4_block9_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block9_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv4_block9_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block9_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv4_block9_out (Add)      (None, 8, 8, 1024)           0         ['conv4_block8_out[0][0]',    \n                                                                     'conv4_block9_3_conv[0][0]'] \n                                                                                                  \n conv4_block10_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block9_out[0][0]']    \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block10_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block10_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block10_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block10_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block10_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block10_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block10_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block10_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block10_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block10_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block10_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block10_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block10_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block10_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block10_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block10_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block10_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block10_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block10_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block9_out[0][0]',    \n                                                                     'conv4_block10_3_conv[0][0]']\n                                                                                                  \n conv4_block11_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block10_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block11_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block11_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block11_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block11_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block11_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block11_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block11_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block11_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block11_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block11_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block11_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block11_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block11_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block11_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block11_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block11_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block11_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block11_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block11_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block10_out[0][0]',   \n                                                                     'conv4_block11_3_conv[0][0]']\n                                                                                                  \n conv4_block12_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block11_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block12_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block12_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block12_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block12_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block12_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block12_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block12_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block12_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block12_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block12_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block12_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block12_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block12_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block12_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block12_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block12_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block12_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block12_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block12_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block11_out[0][0]',   \n                                                                     'conv4_block12_3_conv[0][0]']\n                                                                                                  \n conv4_block13_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block12_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block13_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block13_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block13_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block13_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block13_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block13_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block13_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block13_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block13_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block13_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block13_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block13_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block13_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block13_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block13_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block13_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block13_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block13_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block13_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block12_out[0][0]',   \n                                                                     'conv4_block13_3_conv[0][0]']\n                                                                                                  \n conv4_block14_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block13_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block14_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block14_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block14_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block14_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block14_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block14_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block14_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block14_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block14_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block14_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block14_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block14_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block14_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block14_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block14_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block14_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block14_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block14_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block14_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block13_out[0][0]',   \n                                                                     'conv4_block14_3_conv[0][0]']\n                                                                                                  \n conv4_block15_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block14_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block15_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block15_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block15_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block15_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block15_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block15_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block15_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block15_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block15_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block15_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block15_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block15_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block15_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block15_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block15_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block15_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block15_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block15_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block15_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block14_out[0][0]',   \n                                                                     'conv4_block15_3_conv[0][0]']\n                                                                                                  \n conv4_block16_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block15_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block16_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block16_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block16_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block16_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block16_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block16_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block16_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block16_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block16_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block16_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block16_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block16_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block16_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block16_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block16_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block16_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block16_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block16_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block16_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block15_out[0][0]',   \n                                                                     'conv4_block16_3_conv[0][0]']\n                                                                                                  \n conv4_block17_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block16_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block17_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block17_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block17_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block17_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block17_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block17_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block17_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block17_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block17_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block17_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block17_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block17_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block17_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block17_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block17_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block17_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block17_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block17_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block17_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block16_out[0][0]',   \n                                                                     'conv4_block17_3_conv[0][0]']\n                                                                                                  \n conv4_block18_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block17_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block18_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block18_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block18_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block18_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block18_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block18_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block18_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block18_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block18_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block18_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block18_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block18_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block18_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block18_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block18_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block18_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block18_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block18_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block18_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block17_out[0][0]',   \n                                                                     'conv4_block18_3_conv[0][0]']\n                                                                                                  \n conv4_block19_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block18_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block19_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block19_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block19_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block19_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block19_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block19_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block19_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block19_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block19_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block19_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block19_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block19_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block19_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block19_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block19_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block19_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block19_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block19_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block19_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block18_out[0][0]',   \n                                                                     'conv4_block19_3_conv[0][0]']\n                                                                                                  \n conv4_block20_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block19_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block20_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block20_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block20_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block20_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block20_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block20_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block20_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block20_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block20_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block20_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block20_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block20_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block20_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block20_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block20_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block20_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block20_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block20_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block20_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block19_out[0][0]',   \n                                                                     'conv4_block20_3_conv[0][0]']\n                                                                                                  \n conv4_block21_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block20_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block21_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block21_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block21_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block21_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block21_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block21_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block21_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block21_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block21_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block21_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block21_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block21_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block21_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block21_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block21_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block21_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block21_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block21_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block21_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block20_out[0][0]',   \n                                                                     'conv4_block21_3_conv[0][0]']\n                                                                                                  \n conv4_block22_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block21_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block22_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block22_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block22_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block22_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block22_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block22_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block22_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block22_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block22_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block22_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block22_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block22_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block22_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block22_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block22_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block22_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block22_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block22_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block22_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block21_out[0][0]',   \n                                                                     'conv4_block22_3_conv[0][0]']\n                                                                                                  \n conv4_block23_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block22_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block23_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block23_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block23_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block23_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block23_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block23_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block23_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block23_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block23_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block23_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block23_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block23_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block23_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block23_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block23_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block23_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block23_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block23_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block23_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block22_out[0][0]',   \n                                                                     'conv4_block23_3_conv[0][0]']\n                                                                                                  \n conv4_block24_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block23_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block24_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block24_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block24_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block24_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block24_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block24_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block24_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block24_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block24_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block24_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block24_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block24_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block24_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block24_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block24_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block24_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block24_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block24_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block24_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block23_out[0][0]',   \n                                                                     'conv4_block24_3_conv[0][0]']\n                                                                                                  \n conv4_block25_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block24_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block25_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block25_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block25_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block25_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block25_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block25_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block25_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block25_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block25_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block25_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block25_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block25_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block25_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block25_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block25_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block25_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block25_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block25_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block25_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block24_out[0][0]',   \n                                                                     'conv4_block25_3_conv[0][0]']\n                                                                                                  \n conv4_block26_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block25_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block26_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block26_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block26_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block26_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block26_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block26_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block26_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block26_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block26_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block26_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block26_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block26_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block26_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block26_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block26_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block26_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block26_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block26_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block26_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block25_out[0][0]',   \n                                                                     'conv4_block26_3_conv[0][0]']\n                                                                                                  \n conv4_block27_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block26_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block27_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block27_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block27_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block27_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block27_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block27_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block27_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block27_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block27_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block27_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block27_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block27_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block27_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block27_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block27_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block27_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block27_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block27_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block27_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block26_out[0][0]',   \n                                                                     'conv4_block27_3_conv[0][0]']\n                                                                                                  \n conv4_block28_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block27_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block28_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block28_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block28_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block28_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block28_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block28_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block28_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block28_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block28_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block28_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block28_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block28_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block28_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block28_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block28_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block28_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block28_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block28_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block28_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block27_out[0][0]',   \n                                                                     'conv4_block28_3_conv[0][0]']\n                                                                                                  \n conv4_block29_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block28_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block29_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block29_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block29_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block29_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block29_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block29_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block29_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block29_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block29_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block29_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block29_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block29_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block29_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block29_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block29_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block29_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block29_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block29_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block29_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block28_out[0][0]',   \n                                                                     'conv4_block29_3_conv[0][0]']\n                                                                                                  \n conv4_block30_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block29_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block30_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block30_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block30_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block30_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block30_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block30_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block30_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block30_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block30_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block30_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block30_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block30_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block30_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block30_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block30_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block30_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block30_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block30_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block30_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block29_out[0][0]',   \n                                                                     'conv4_block30_3_conv[0][0]']\n                                                                                                  \n conv4_block31_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block30_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block31_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block31_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block31_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block31_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block31_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block31_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block31_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block31_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block31_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block31_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block31_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block31_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block31_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block31_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block31_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block31_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block31_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block31_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block31_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block30_out[0][0]',   \n                                                                     'conv4_block31_3_conv[0][0]']\n                                                                                                  \n conv4_block32_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block31_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block32_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block32_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block32_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block32_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block32_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block32_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block32_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block32_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block32_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block32_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block32_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block32_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block32_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block32_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block32_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block32_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block32_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block32_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block32_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block31_out[0][0]',   \n                                                                     'conv4_block32_3_conv[0][0]']\n                                                                                                  \n conv4_block33_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block32_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block33_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block33_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block33_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block33_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block33_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block33_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block33_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block33_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block33_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block33_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block33_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block33_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block33_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block33_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block33_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block33_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block33_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block33_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block33_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block32_out[0][0]',   \n                                                                     'conv4_block33_3_conv[0][0]']\n                                                                                                  \n conv4_block34_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block33_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block34_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block34_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block34_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block34_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block34_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block34_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block34_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block34_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block34_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block34_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block34_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block34_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block34_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block34_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block34_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block34_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block34_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block34_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block34_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block33_out[0][0]',   \n                                                                     'conv4_block34_3_conv[0][0]']\n                                                                                                  \n conv4_block35_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block34_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block35_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block35_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block35_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block35_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block35_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block35_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block35_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block35_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block35_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block35_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block35_2_conv (Conv  (None, 8, 8, 256)            589824    ['conv4_block35_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block35_2_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block35_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block35_2_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block35_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block35_3_conv (Conv  (None, 8, 8, 1024)           263168    ['conv4_block35_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block35_out (Add)     (None, 8, 8, 1024)           0         ['conv4_block34_out[0][0]',   \n                                                                     'conv4_block35_3_conv[0][0]']\n                                                                                                  \n conv4_block36_preact_bn (B  (None, 8, 8, 1024)           4096      ['conv4_block35_out[0][0]']   \n atchNormalization)                                                                               \n                                                                                                  \n conv4_block36_preact_relu   (None, 8, 8, 1024)           0         ['conv4_block36_preact_bn[0][0\n (Activation)                                                       ]']                           \n                                                                                                  \n conv4_block36_1_conv (Conv  (None, 8, 8, 256)            262144    ['conv4_block36_preact_relu[0]\n 2D)                                                                [0]']                         \n                                                                                                  \n conv4_block36_1_bn (BatchN  (None, 8, 8, 256)            1024      ['conv4_block36_1_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block36_1_relu (Acti  (None, 8, 8, 256)            0         ['conv4_block36_1_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n conv4_block36_2_pad (ZeroP  (None, 10, 10, 256)          0         ['conv4_block36_1_relu[0][0]']\n adding2D)                                                                                        \n                                                                                                  \n conv4_block36_2_conv (Conv  (None, 4, 4, 256)            589824    ['conv4_block36_2_pad[0][0]'] \n 2D)                                                                                              \n                                                                                                  \n conv4_block36_2_bn (BatchN  (None, 4, 4, 256)            1024      ['conv4_block36_2_conv[0][0]']\n ormalization)                                                                                    \n                                                                                                  \n conv4_block36_2_relu (Acti  (None, 4, 4, 256)            0         ['conv4_block36_2_bn[0][0]']  \n vation)                                                                                          \n                                                                                                  \n max_pooling2d_2 (MaxPoolin  (None, 4, 4, 1024)           0         ['conv4_block35_out[0][0]']   \n g2D)                                                                                             \n                                                                                                  \n conv4_block36_3_conv (Conv  (None, 4, 4, 1024)           263168    ['conv4_block36_2_relu[0][0]']\n 2D)                                                                                              \n                                                                                                  \n conv4_block36_out (Add)     (None, 4, 4, 1024)           0         ['max_pooling2d_2[0][0]',     \n                                                                     'conv4_block36_3_conv[0][0]']\n                                                                                                  \n conv5_block1_preact_bn (Ba  (None, 4, 4, 1024)           4096      ['conv4_block36_out[0][0]']   \n tchNormalization)                                                                                \n                                                                                                  \n conv5_block1_preact_relu (  (None, 4, 4, 1024)           0         ['conv5_block1_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv5_block1_1_conv (Conv2  (None, 4, 4, 512)            524288    ['conv5_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv5_block1_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block1_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block1_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv5_block1_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv5_block1_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block1_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block1_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block1_0_conv (Conv2  (None, 4, 4, 2048)           2099200   ['conv5_block1_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv5_block1_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block1_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_0_conv[0][0]', \n                                                                     'conv5_block1_3_conv[0][0]'] \n                                                                                                  \n conv5_block2_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block1_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv5_block2_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block2_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv5_block2_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block2_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv5_block2_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block2_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block2_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv5_block2_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv5_block2_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block2_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block2_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block2_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block2_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block1_out[0][0]',    \n                                                                     'conv5_block2_3_conv[0][0]'] \n                                                                                                  \n conv5_block3_preact_bn (Ba  (None, 4, 4, 2048)           8192      ['conv5_block2_out[0][0]']    \n tchNormalization)                                                                                \n                                                                                                  \n conv5_block3_preact_relu (  (None, 4, 4, 2048)           0         ['conv5_block3_preact_bn[0][0]\n Activation)                                                        ']                            \n                                                                                                  \n conv5_block3_1_conv (Conv2  (None, 4, 4, 512)            1048576   ['conv5_block3_preact_relu[0][\n D)                                                                 0]']                          \n                                                                                                  \n conv5_block3_1_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_1_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_1_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block3_2_pad (ZeroPa  (None, 6, 6, 512)            0         ['conv5_block3_1_relu[0][0]'] \n dding2D)                                                                                         \n                                                                                                  \n conv5_block3_2_conv (Conv2  (None, 4, 4, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n D)                                                                                               \n                                                                                                  \n conv5_block3_2_bn (BatchNo  (None, 4, 4, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n rmalization)                                                                                     \n                                                                                                  \n conv5_block3_2_relu (Activ  (None, 4, 4, 512)            0         ['conv5_block3_2_bn[0][0]']   \n ation)                                                                                           \n                                                                                                  \n conv5_block3_3_conv (Conv2  (None, 4, 4, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n D)                                                                                               \n                                                                                                  \n conv5_block3_out (Add)      (None, 4, 4, 2048)           0         ['conv5_block2_out[0][0]',    \n                                                                     'conv5_block3_3_conv[0][0]'] \n                                                                                                  \n post_bn (BatchNormalizatio  (None, 4, 4, 2048)           8192      ['conv5_block3_out[0][0]']    \n n)                                                                                               \n                                                                                                  \n post_relu (Activation)      (None, 4, 4, 2048)           0         ['post_bn[0][0]']             \n                                                                                                  \n global_average_pooling2d (  (None, 2048)                 0         ['post_relu[0][0]']           \n GlobalAveragePooling2D)                                                                          \n                                                                                                  \n dropout (Dropout)           (None, 2048)                 0         ['global_average_pooling2d[0][\n                                                                    0]']                          \n                                                                                                  \n dense (Dense)               (None, 2)                    4098      ['dropout[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 58335746 (222.53 MB)\nTrainable params: 58192002 (221.98 MB)\nNon-trainable params: 143744 (561.50 KB)\n__________________________________________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We finally compile our model.","metadata":{}},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:48.682039Z","iopub.execute_input":"2023-11-14T16:18:48.682593Z","iopub.status.idle":"2023-11-14T16:18:48.972797Z","shell.execute_reply.started":"2023-11-14T16:18:48.682564Z","shell.execute_reply":"2023-11-14T16:18:48.971841Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"**Callbacks** -> Callbacks can help you fix bugs more quickly, and can help you build better models. They can help you visualize how your model’s training is going, and can even help prevent overfitting by implementing early stopping or customizing the learning rate on each iteration.<br><br>\nBy definition, \"A callback is a set of functions to be applied at given stages of the training procedure. You can use callbacks to get a view on internal states and statistics of the model during training.\"\n\nIn this notebook, I'll be using **TensorBoard, ModelCheckpoint and ReduceLROnPlateau** callback functions","metadata":{}},{"cell_type":"code","source":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"resnet152v1.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.4, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:18:48.974235Z","iopub.execute_input":"2023-11-14T16:18:48.974543Z","iopub.status.idle":"2023-11-14T16:18:49.442650Z","shell.execute_reply.started":"2023-11-14T16:18:48.974516Z","shell.execute_reply":"2023-11-14T16:18:49.441547Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Training The Model","metadata":{}},{"cell_type":"code","source":"history = model.fit(X_train,y_train,validation_split=0.1, epochs =10, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-14T16:18:49.443897Z","iopub.execute_input":"2023-11-14T16:18:49.444265Z","iopub.status.idle":"2023-11-14T16:25:14.921351Z","shell.execute_reply.started":"2023-11-14T16:18:49.444237Z","shell.execute_reply":"2023-11-14T16:25:14.920510Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Epoch 1/10\n149/149 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9283\nEpoch 1: val_accuracy improved from -inf to 0.71917, saving model to resnet152v1.h5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n  saving_api.save_model(\n","output_type":"stream"},{"name":"stdout","text":"149/149 [==============================] - 133s 224ms/step - loss: 0.1839 - accuracy: 0.9283 - val_loss: 8.0931 - val_accuracy: 0.7192 - lr: 0.0010\nEpoch 2/10\n149/149 [==============================] - ETA: 0s - loss: 0.1121 - accuracy: 0.9597\nEpoch 2: val_accuracy did not improve from 0.71917\n149/149 [==============================] - 26s 178ms/step - loss: 0.1121 - accuracy: 0.9597 - val_loss: 3.3452 - val_accuracy: 0.7135 - lr: 0.0010\nEpoch 3/10\n149/149 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9705\nEpoch 3: val_accuracy improved from 0.71917 to 0.90323, saving model to resnet152v1.h5\n149/149 [==============================] - 29s 197ms/step - loss: 0.0839 - accuracy: 0.9705 - val_loss: 0.3167 - val_accuracy: 0.9032 - lr: 0.0010\nEpoch 4/10\n149/149 [==============================] - ETA: 0s - loss: 0.0623 - accuracy: 0.9774\nEpoch 4: val_accuracy improved from 0.90323 to 0.90512, saving model to resnet152v1.h5\n149/149 [==============================] - 29s 195ms/step - loss: 0.0623 - accuracy: 0.9774 - val_loss: 0.2675 - val_accuracy: 0.9051 - lr: 0.0010\nEpoch 5/10\n149/149 [==============================] - ETA: 0s - loss: 0.0787 - accuracy: 0.9686\nEpoch 5: val_accuracy did not improve from 0.90512\n149/149 [==============================] - 26s 177ms/step - loss: 0.0787 - accuracy: 0.9686 - val_loss: 0.9692 - val_accuracy: 0.8463 - lr: 0.0010\nEpoch 6/10\n149/149 [==============================] - ETA: 0s - loss: 0.1716 - accuracy: 0.9378\nEpoch 6: val_accuracy improved from 0.90512 to 0.94307, saving model to resnet152v1.h5\n149/149 [==============================] - 29s 197ms/step - loss: 0.1716 - accuracy: 0.9378 - val_loss: 0.2337 - val_accuracy: 0.9431 - lr: 0.0010\nEpoch 7/10\n149/149 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9639\nEpoch 7: val_accuracy improved from 0.94307 to 0.95446, saving model to resnet152v1.h5\n149/149 [==============================] - 29s 196ms/step - loss: 0.1026 - accuracy: 0.9639 - val_loss: 0.1817 - val_accuracy: 0.9545 - lr: 0.0010\nEpoch 8/10\n149/149 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9730\nEpoch 8: val_accuracy did not improve from 0.95446\n149/149 [==============================] - 26s 177ms/step - loss: 0.0742 - accuracy: 0.9730 - val_loss: 2.9835 - val_accuracy: 0.7211 - lr: 0.0010\nEpoch 9/10\n149/149 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9777\nEpoch 9: val_accuracy did not improve from 0.95446\n\nEpoch 9: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n149/149 [==============================] - 26s 177ms/step - loss: 0.0635 - accuracy: 0.9777 - val_loss: 1.0044 - val_accuracy: 0.8463 - lr: 0.0010\nEpoch 10/10\n149/149 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9899\nEpoch 10: val_accuracy improved from 0.95446 to 0.96964, saving model to resnet152v1.h5\n149/149 [==============================] - 29s 196ms/step - loss: 0.0338 - accuracy: 0.9899 - val_loss: 0.0910 - val_accuracy: 0.9696 - lr: 4.0000e-04\n","output_type":"stream"}]},{"cell_type":"code","source":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-11-14T16:25:14.922865Z","iopub.execute_input":"2023-11-14T16:25:14.923841Z","iopub.status.idle":"2023-11-14T16:25:15.373009Z","shell.execute_reply.started":"2023-11-14T16:25:14.923807Z","shell.execute_reply":"2023-11-14T16:25:15.372060Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"train_dir = \"/kaggle/input/labeled-chest-xray-images/chest_xray/train\"\ntest_dir = \"/kaggle/input/labeled-chest-xray-images/chest_xray/test\"","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:26:34.059277Z","iopub.execute_input":"2023-11-14T16:26:34.060257Z","iopub.status.idle":"2023-11-14T16:26:34.064649Z","shell.execute_reply.started":"2023-11-14T16:26:34.060214Z","shell.execute_reply":"2023-11-14T16:26:34.063553Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\ntrain_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n                                                                 image_size=(128,128),\n                                                                 label_mode = \"categorical\",\n                                                                 batch_size = 32\n                                                                 )\ntest_data =tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n                                                               image_size =(128,128),\n                                                               label_mode = \"categorical\",\n                                                               batch_size = 32\n                                                               )","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:26:37.370569Z","iopub.execute_input":"2023-11-14T16:26:37.370953Z","iopub.status.idle":"2023-11-14T16:26:43.366041Z","shell.execute_reply.started":"2023-11-14T16:26:37.370922Z","shell.execute_reply":"2023-11-14T16:26:43.365303Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Found 5232 files belonging to 2 classes.\nFound 624 files belonging to 2 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"pred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\ny_test_new = np.argmax(y_test,axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:26:43.759151Z","iopub.execute_input":"2023-11-14T16:26:43.759519Z","iopub.status.idle":"2023-11-14T16:26:48.028292Z","shell.execute_reply.started":"2023-11-14T16:26:43.759488Z","shell.execute_reply":"2023-11-14T16:26:48.027442Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"19/19 [==============================] - 4s 81ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classification_report(y_test_new,pred))","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:27:03.599533Z","iopub.execute_input":"2023-11-14T16:27:03.599890Z","iopub.status.idle":"2023-11-14T16:27:03.614346Z","shell.execute_reply.started":"2023-11-14T16:27:03.599865Z","shell.execute_reply":"2023-11-14T16:27:03.613410Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n           0       0.99      0.88      0.93       168\n           1       0.95      1.00      0.97       418\n\n    accuracy                           0.96       586\n   macro avg       0.97      0.94      0.95       586\nweighted avg       0.96      0.96      0.96       586\n\n","output_type":"stream"}]},{"cell_type":"code","source":"fig,ax=plt.subplots(1,1,figsize=(14,7))\nsns.heatmap(confusion_matrix(y_test_new,pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True,\n           cmap=colors_green[::-1],alpha=0.7,linewidths=2,linecolor=colors_dark[3])\nfig.text(s='Heatmap of the Confusion Matrix',size=18,fontweight='bold',\n             fontname='monospace',color=colors_dark[1],y=0.92,x=0.28,alpha=0.8)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:27:06.823053Z","iopub.execute_input":"2023-11-14T16:27:06.823506Z","iopub.status.idle":"2023-11-14T16:27:07.137867Z","shell.execute_reply.started":"2023-11-14T16:27:06.823460Z","shell.execute_reply":"2023-11-14T16:27:07.136936Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1400x700 with 2 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nfrom PIL import Image\n\ndef img_pred(file_path):\n    img = Image.open(file_path)\n    opencvImage = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n    img = cv2.resize(opencvImage, (150, 150))\n    img = img.reshape(1, 150, 150, 3)\n    p = model.predict(img)\n    p = np.argmax(p, axis=1)[0]\n\n    if p == 0:\n        p = 'NORMAL'\n    else:\n        p = 'PNEUMONIA'\n\n    return f'The Model predicts that it is a {p}'\n\nresult = img_pred('/kaggle/input/labeled-chest-xray-images/chest_xray/test/NORMAL/NORMAL-1110860-0001.jpeg')\nprint(result)","metadata":{"execution":{"iopub.status.busy":"2023-11-14T16:32:38.437346Z","iopub.execute_input":"2023-11-14T16:32:38.438036Z","iopub.status.idle":"2023-11-14T16:32:38.544352Z","shell.execute_reply.started":"2023-11-14T16:32:38.438005Z","shell.execute_reply":"2023-11-14T16:32:38.543489Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 30ms/step\nThe Model predicts that it is a NORMAL\n","output_type":"stream"}]}]}